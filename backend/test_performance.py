#!/usr/bin/env python3
"""
æ¶æ„é‡æ„æ€§èƒ½æµ‹è¯•è„šæœ¬
"""
import time
import concurrent.futures
import requests
import statistics
from services.database import get_db_pool

def test_api_performance():
    """æµ‹è¯•APIå“åº”æ€§èƒ½"""
    base_url = "http://127.0.0.1:5001"
    endpoints = [
        "/api/health",
        "/api/content",
        "/api/admin/check"
    ]
    
    print("ğŸš€ APIæ€§èƒ½æµ‹è¯•å¼€å§‹...")
    
    for endpoint in endpoints:
        url = f"{base_url}{endpoint}"
        response_times = []
        
        # è¿›è¡Œ10æ¬¡è¯·æ±‚æµ‹è¯•
        for i in range(10):
            start_time = time.time()
            try:
                response = requests.get(url, timeout=5)
                end_time = time.time()
                
                if response.status_code == 200:
                    response_times.append((end_time - start_time) * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
                else:
                    print(f"âŒ {endpoint} è¿”å›çŠ¶æ€ç : {response.status_code}")
            except Exception as e:
                print(f"âŒ {endpoint} è¯·æ±‚å¤±è´¥: {e}")
        
        if response_times:
            avg_time = statistics.mean(response_times)
            min_time = min(response_times)
            max_time = max(response_times)
            
            print(f"âœ… {endpoint}")
            print(f"   å¹³å‡å“åº”æ—¶é—´: {avg_time:.2f}ms")
            print(f"   æœ€å¿«å“åº”æ—¶é—´: {min_time:.2f}ms")
            print(f"   æœ€æ…¢å“åº”æ—¶é—´: {max_time:.2f}ms")
        print()

def test_database_pool():
    """æµ‹è¯•æ•°æ®åº“è¿æ¥æ± æ€§èƒ½"""
    print("ğŸ—„ï¸ æ•°æ®åº“è¿æ¥æ± æµ‹è¯•å¼€å§‹...")
    
    pool = get_db_pool()
    
    # æ˜¾ç¤ºè¿æ¥æ± åˆå§‹çŠ¶æ€
    stats = pool.get_stats()
    print(f"åˆå§‹è¿æ¥æ± çŠ¶æ€:")
    print(f"  æœ€å¤§è¿æ¥æ•°: {stats['max_connections']}")
    print(f"  å½“å‰è¿æ¥æ•°: {stats['created_connections']}")
    print(f"  å¯ç”¨è¿æ¥æ•°: {stats['available_connections']}")
    print()
    
    def execute_query(query_id):
        """æ‰§è¡Œå•ä¸ªæ•°æ®åº“æŸ¥è¯¢"""
        start_time = time.time()
        try:
            with pool.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT COUNT(*) as count FROM text_content")
                result = cursor.fetchone()
                end_time = time.time()
                return {
                    'query_id': query_id,
                    'success': True,
                    'time': (end_time - start_time) * 1000,
                    'result': dict(result) if result else None
                }
        except Exception as e:
            end_time = time.time()
            return {
                'query_id': query_id,
                'success': False,
                'time': (end_time - start_time) * 1000,
                'error': str(e)
            }
    
    # å¹¶å‘æµ‹è¯•
    print("æ‰§è¡Œå¹¶å‘æ•°æ®åº“æŸ¥è¯¢æµ‹è¯•...")
    concurrent_queries = 20
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        futures = [executor.submit(execute_query, i) for i in range(concurrent_queries)]
        results = [future.result() for future in concurrent.futures.as_completed(futures)]
    
    # åˆ†æç»“æœ
    successful_queries = [r for r in results if r['success']]
    failed_queries = [r for r in results if not r['success']]
    
    if successful_queries:
        response_times = [r['time'] for r in successful_queries]
        avg_time = statistics.mean(response_times)
        min_time = min(response_times)
        max_time = max(response_times)
        
        print(f"âœ… å¹¶å‘æŸ¥è¯¢ç»“æœ:")
        print(f"   æˆåŠŸæŸ¥è¯¢: {len(successful_queries)}/{concurrent_queries}")
        print(f"   å¤±è´¥æŸ¥è¯¢: {len(failed_queries)}")
        print(f"   å¹³å‡æŸ¥è¯¢æ—¶é—´: {avg_time:.2f}ms")
        print(f"   æœ€å¿«æŸ¥è¯¢æ—¶é—´: {min_time:.2f}ms")
        print(f"   æœ€æ…¢æŸ¥è¯¢æ—¶é—´: {max_time:.2f}ms")
    
    if failed_queries:
        print(f"âŒ å¤±è´¥çš„æŸ¥è¯¢:")
        for failed in failed_queries[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªé”™è¯¯
            print(f"   æŸ¥è¯¢ {failed['query_id']}: {failed['error']}")
    
    # æ˜¾ç¤ºè¿æ¥æ± æœ€ç»ˆçŠ¶æ€
    final_stats = pool.get_stats()
    print(f"\nè¿æ¥æ± æœ€ç»ˆçŠ¶æ€:")
    print(f"  åˆ›å»ºçš„è¿æ¥æ•°: {final_stats['created_connections']}")
    print(f"  å¯ç”¨è¿æ¥æ•°: {final_stats['available_connections']}")
    print()

def test_concurrent_api_requests():
    """æµ‹è¯•å¹¶å‘APIè¯·æ±‚"""
    print("ğŸ”„ å¹¶å‘APIè¯·æ±‚æµ‹è¯•å¼€å§‹...")
    
    base_url = "http://127.0.0.1:5001"
    endpoint = "/api/content"
    concurrent_requests = 15
    
    def make_request(request_id):
        """å‘èµ·å•ä¸ªAPIè¯·æ±‚"""
        start_time = time.time()
        try:
            response = requests.get(f"{base_url}{endpoint}", timeout=10)
            end_time = time.time()
            return {
                'request_id': request_id,
                'success': response.status_code == 200,
                'time': (end_time - start_time) * 1000,
                'status_code': response.status_code
            }
        except Exception as e:
            end_time = time.time()
            return {
                'request_id': request_id,
                'success': False,
                'time': (end_time - start_time) * 1000,
                'error': str(e)
            }
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        futures = [executor.submit(make_request, i) for i in range(concurrent_requests)]
        results = [future.result() for future in concurrent.futures.as_completed(futures)]
    
    successful_requests = [r for r in results if r['success']]
    failed_requests = [r for r in results if not r['success']]
    
    if successful_requests:
        response_times = [r['time'] for r in successful_requests]
        avg_time = statistics.mean(response_times)
        min_time = min(response_times)
        max_time = max(response_times)
        
        print(f"âœ… å¹¶å‘APIè¯·æ±‚ç»“æœ:")
        print(f"   æˆåŠŸè¯·æ±‚: {len(successful_requests)}/{concurrent_requests}")
        print(f"   å¤±è´¥è¯·æ±‚: {len(failed_requests)}")
        print(f"   å¹³å‡å“åº”æ—¶é—´: {avg_time:.2f}ms")
        print(f"   æœ€å¿«å“åº”æ—¶é—´: {min_time:.2f}ms")
        print(f"   æœ€æ…¢å“åº”æ—¶é—´: {max_time:.2f}ms")
    
    if failed_requests:
        print(f"âŒ å¤±è´¥çš„è¯·æ±‚:")
        for failed in failed_requests[:3]:
            print(f"   è¯·æ±‚ {failed['request_id']}: {failed.get('error', 'çŠ¶æ€ç é”™è¯¯')}")
    print()

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ§ª æ™ºæŠ¤ç«¥è¡Œæ¶æ„é‡æ„æ€§èƒ½æµ‹è¯•")
    print("=" * 60)
    print()
    
    try:
        # 1. APIæ€§èƒ½æµ‹è¯•
        test_api_performance()
        
        # 2. æ•°æ®åº“è¿æ¥æ± æµ‹è¯•
        test_database_pool()
        
        # 3. å¹¶å‘APIè¯·æ±‚æµ‹è¯•
        test_concurrent_api_requests()
        
        print("=" * 60)
        print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        print("=" * 60)
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        print("è¯·ç¡®ä¿åç«¯æœåŠ¡æ­£åœ¨è¿è¡Œ (python3 app.py)")
